{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3252c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd01926",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset klaid (C:/Users/victolee/.cache/huggingface/datasets/klaid/ljp/1.0.0/3555cf1de16633bfd57ee9b1e854f43f3544b2c235bfbf0cca33b5056612fbef)\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# legal judgment prediction\n",
    "dataset = load_dataset(\"/KLAID/KLAID.py\", 'ljp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af94754",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('label.csv').iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b370430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "laws = [None] * len(dataset['train'])\n",
    "for i, val in enumerate(dataset['train']):\n",
    "    laws[i] = data.iloc[val['laws_service_id']]['laws']\n",
    "train = dataset['train'].add_column(\"laws\", laws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7caaf8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'beomi/KcELECTRA-base-v2022'\n",
    "q_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "p_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "q_seqs = q_tokenizer(train['fact'], padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "p_seqs = p_tokenizer(train['laws'], padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "train_dataset = TensorDataset(p_seqs['input_ids'], p_seqs['attention_mask'], p_seqs['token_type_ids'], \n",
    "                        q_seqs['input_ids'], q_seqs['attention_mask'], q_seqs['token_type_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe34b378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "q_model = AutoModel.from_pretrained(model_name)\n",
    "p_model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45cef350",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'random_seed': 42, # Random Seed\n",
    "    'pretrained_model': 'beomi/KcELECTRA-base',  # Transformers PLM name\n",
    "    'pretrained_tokenizer': '',  # Optional, Transformers Tokenizer Name. Overrides `pretrained_model`\n",
    "    'batch_size': 32,\n",
    "    'lr': 5e-6,  # Starting Learning Rate\n",
    "    'epochs': 50,  # Max Epochs\n",
    "    'max_length': 150,  # Max Length input size\n",
    "    'num_train_epochs': 3,\n",
    "    'adam_epsilon': 1e-08,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'warmup_steps': 5,\n",
    "    'weight_decay': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fcbaf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 0/5038 [00:00<?, ?it/s]\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [56], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m p_model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m---> 37\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(t\u001b[39m.\u001b[39;49mcuda() \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m batch)\n\u001b[0;32m     39\u001b[0m     p_inputs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m0\u001b[39m],\n\u001b[0;32m     40\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m1\u001b[39m],\n\u001b[0;32m     41\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m2\u001b[39m]\n\u001b[0;32m     42\u001b[0m                 }\n\u001b[0;32m     44\u001b[0m     q_inputs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m3\u001b[39m],\n\u001b[0;32m     45\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m4\u001b[39m],\n\u001b[0;32m     46\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m5\u001b[39m]}\n",
      "Cell \u001b[1;32mIn [56], line 37\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     34\u001b[0m p_model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m---> 37\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(t\u001b[39m.\u001b[39;49mcuda() \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m batch)\n\u001b[0;32m     39\u001b[0m     p_inputs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m0\u001b[39m],\n\u001b[0;32m     40\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m1\u001b[39m],\n\u001b[0;32m     41\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m2\u001b[39m]\n\u001b[0;32m     42\u001b[0m                 }\n\u001b[0;32m     44\u001b[0m     q_inputs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m3\u001b[39m],\n\u001b[0;32m     45\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m4\u001b[39m],\n\u001b[0;32m     46\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m5\u001b[39m]}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "train_sampler = RandomSampler(train)\n",
    "train_dataloader = DataLoader(train, sampler=train_sampler, batch_size=args['batch_size'])\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in p_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
    "    {'params': [p for n, p in p_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    {'params': [p for n, p in q_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
    "    {'params': [p for n, p in q_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "######\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args['lr'], eps=args['adam_epsilon'])\n",
    "\n",
    "# 총학습 길이를 계산해서 scheduler에 넣어주기\n",
    "t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['epochs']\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args['warmup_steps'], num_training_steps=t_total)\n",
    "\n",
    "# 학습 초기, 초기화\n",
    "# optimizer.zero_grad() -> 설정해준 파라미터만 초기화\n",
    "# model.zero_grad() -> 모델의 전체 파라미터를 초기화\n",
    "p_model.zero_grad()\n",
    "q_model.zero_grad()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n",
    "batch_loss = 0\n",
    "\n",
    "# 학습 루프 시작!\n",
    "for _ in train_iterator:\n",
    "    print(_)\n",
    "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    # batch 단위로 꺼내오기\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        q_model.train()\n",
    "        p_model.train()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "            p_inputs = {'input_ids': batch[0],\n",
    "                        'attention_mask': batch[1],\n",
    "                        'token_type_ids': batch[2]\n",
    "                        }\n",
    "            \n",
    "            q_inputs = {'input_ids': batch[3],\n",
    "                        'attention_mask': batch[4],\n",
    "                        'token_type_ids': batch[5]}\n",
    "            \n",
    "            p_outputs = p_model(**p_inputs).pooler_output # pooler_output이 [CLS] 토큰의 임베딩 벡터\n",
    "            q_outputs = q_model(**q_inputs).pooler_output\n",
    "\n",
    "            # 유사도 구하기 (batch_size * embedding_dims) * (embedding_dims, batch_size)\n",
    "            sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs, 0, 1))\n",
    "\n",
    "            targets = torch.arange(0, args['per_device_train_batch_size']).long()\n",
    "        if torch.cuda.is_available():\n",
    "            targets = targets.to('cuda')\n",
    "\n",
    "            # log softmax를 취하고 nll_loss를 계산\n",
    "            sim_scores = F.log_softmax(sim_scores, dim=1)\n",
    "            loss = F.nll_loss(sim_scores, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            q_model.zero_grad()\n",
    "            p_model.zero_grad()\n",
    "            batch_loss += loss.detach().cpu().numpy()\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8eb5de80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laws_service_id', 'fact', 'laws_service', 'laws']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce944547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'laws_service_id': 32,\n",
       " 'fact': '피고인은 2018. 8. 9. 23:33경 술을 마신 상태로 경산시 사동에 있는 상호 불상의 식당에서부터 같은 동에 있는 부영5차 앞 삼거리까지 B 스타렉스 승용차를 운전한 다음 승용차 안에서 잠을 자던 중, 차량 운전자가 시동을 걸어 놓고 잠을 자고 있다는 112 신고를 받고 현장에 출동한 경산경찰서 C파출소 소속 경위 D으로부터 피고인의 입에서 술 냄새가 나고 보행이 비틀거리는 등 술에 취한 상태에서 운전하였다고 인정할 만한 상당한 이유가 있어 약 10분 동안 총 3회에 걸쳐 음주측정기에 입김을 불어 넣는 방법으로 음주측정에 응할 것을 요구받고도 정당한 사유 없이 이에 응하지 아니하였다.',\n",
       " 'laws_service': '도로교통법 제148조의2 제2항,도로교통법 제44조 제2항',\n",
       " 'laws': '도로교통법 제148조의2 제2항 술에 취한 상태에 있다고 인정할 만한 상당한 이유가 있는 사람으로서 도로교통법 제44조제2항에 따른 경찰공무원의 측정에 응하지 아니하는 사람(자동차등 또는 노면전차를 운전하는 사람으로 한정한다)은 1년 이상 5년 이하의 징역이나 500만원 이상 2천만원 이하의 벌금에 처한다. \\\\n 도로교통법 제44조 제2항  경찰공무원은 교통의 안전과 위험방지를 위하여 필요하다고 인정하거나 제1항을 위반하여 술에 취한 상태에서 자동차등, 노면전차 또는 자전거를 운전하였다고 인정할 만한 상당한 이유가 있는 경우에는 운전자가 술에 취하였는지를 호흡조사로 측정할 수 있다. 이 경우 운전자는 경찰공무원의 측정에 응하여야 한다.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ea22a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "klaid",
   "language": "python",
   "name": "klaid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
